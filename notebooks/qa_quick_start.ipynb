{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "destroyed-trading",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "This notebook gives the bare minimum steps needed to run the ELI5 QA system, using the code in src/qa_utils.py. \n",
    "\n",
    "If you are looking for an understanding of what's going on under the hood, look at the [qa_step_by_step.ipynb](qa_step_by_step.ipynb) notebook and of course the original blog post itself: https://yjernite.github.io/lfqa.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "everyday-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../src\") # where the source code lies\n",
    "\n",
    "import torch as torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "from qa_utils import embed_passages, make_index, QAKnowledgeBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-olive",
   "metadata": {},
   "source": [
    "# Making the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wiki_snippets (/home/rob/.cache/huggingface/datasets/wiki_snippets/wiki40b_en_100_0/1.0.0/d152a0e6a420c02b9b26e7f75f45fb54c818cae1d83e8f164f0b1a13ac7998ae)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44edc0c0a1f8440aac26177f1e1e8a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset\n",
    "wiki40b_snippets = load_dataset(\"wiki_snippets\", name = \"wiki40b_en_100_0\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genetic-exception",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RetriBertModel were not initialized from the model checkpoint at yjernite/retribert-base-uncased and are newly initialized: ['bert_query.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the RETRIBERT model for embedding the wiki40b_snippet passages\n",
    "qar_tokenizer = AutoTokenizer.from_pretrained('yjernite/retribert-base-uncased')\n",
    "qar_model = AutoModel.from_pretrained('yjernite/retribert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arabic-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to embed\n",
      "embedding 512 passages in 2 separate batches\n",
      "embedding batch 0 of 2 batches 256 passages in batch at time 0.0013992786407470703\n"
     ]
    }
   ],
   "source": [
    "# make the embeddings for the index. This will take about 15 hours if you do the full dataset\n",
    "\n",
    "index_filename = \"../wiki_embeddings/test_embed.dat\" # change this to the full file path where you want to store the index\n",
    "\n",
    "#Note, if the file exists, running embed passages will overwrite it. Be careful and don't do that!\n",
    "if not os.path.isfile(index_filename): # here as a safety measure\n",
    "    print(\"starting to embed\")\n",
    "    embed_passages(wiki40b_snippets, \n",
    "                   qar_tokenizer, \n",
    "                   qar_model, \n",
    "                   n_batches = 2, # REMOVE THIS LINE TO EMBED THE ENTIRE DATA SET!!!!!\n",
    "                   index_file_name = index_filename,\n",
    "                   device=\"cuda:0\")\n",
    "else:\n",
    "    print(\"file already exists are you sure you want to overwrite and re-embed?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-yield",
   "metadata": {},
   "source": [
    "# Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exotic-emission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Putting index on cpu.\n"
     ]
    }
   ],
   "source": [
    "# Make the index from the saved embeddings\n",
    "full_index_filename = \"../wiki_embeddings/wiki_index_embed.dat\"\n",
    "wiki40b_index = make_index(full_index_filename, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "material-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the BART model that is fine-tuned on the ELI5 task\n",
    "qa_s2s_tokenizer = AutoTokenizer.from_pretrained('yjernite/bart_eli5')\n",
    "qa_s2s_model = AutoModelForSeq2SeqLM.from_pretrained('yjernite/bart_eli5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "olive-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an instance of the QAKnowledgeBase class\n",
    "qakb = QAKnowledgeBase(qar_model, qar_tokenizer, qa_s2s_model, qa_s2s_tokenizer, wiki40b_index, wiki40b_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statewide-infrared",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birds use their wings to generate lift. When they flap their wings, the up and down motion of the wing pushes the air in front of them, creating lift.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and ask a question with the ask_question method\n",
    "qakb.ask_question(\"How do birds fly?\", max_answer_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "announced-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>  Flapping involves two stages: the downstroke, which provides the thrust, and the upstroke, *which can also* provide some thrust. The bird can also adjust its wing angle between each flapping stroke, allowing the wing to generate lift on both the up and downstroke. Birds have much',\n",
       " 'They flap their wings with up and down thrusts. The difference being they have a large number of tiny muscles in them which create a tremendous amount of energy.',\n",
       " \"They have 2 arms, each with a different angle, their up/down movement is proportional to their wing's angle. They use a special flap between the legs of the bird so it can generate lift.\",\n",
       " 'They use their talons to generate lift. They then flap their wings. The wings make the air that is behind them lift. This works for a small bird, and for a large bird, too.',\n",
       " 'Birds have small wings but they use their weight to fly. They\\'re very light and have a high efficiency to make lift. So when birds flap their wings, the airflow is pushed upwards. Like an old airplane wing, the air is pushed on the \"back\" side of the wing by the wind around it']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want multiple answers use this method.they can be a little nutty\n",
    "qakb.get_best_answers(\"How do birds fly?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80665a8f",
   "metadata": {},
   "source": [
    "So it works, sort of! Have fun playing around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750adb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
